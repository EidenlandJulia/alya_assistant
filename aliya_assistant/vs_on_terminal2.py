# -*- coding: utf-8 -*-
import os, re, sys
from datetime import datetime
from collections import Counter
from dotenv import load_dotenv
from colorama import Fore, Style, init
import openai

# ========== –ù–ê–°–¢–†–û–ô–ö–ò ==========
CLEAR = False  # –Ω–µ –æ—á–∏—â–∞–µ–º —ç–∫—Ä–∞–Ω
MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
KB_PATH = os.getenv("KB_PATH", "knowledge_base_aliyah_full.txt")

# ========== –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ==========
init(autoreset=True)
load_dotenv()

client = openai.OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    base_url=os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
)

def clear():
    if CLEAR:
        os.system("cls" if os.name == "nt" else "clear")

def load_kb(path: str) -> str:
    print(f"üìÑ –ó–∞–≥—Ä—É–∂–∞—é –±–∞–∑—É –∑–Ω–∞–Ω–∏–π: {os.path.abspath(path)}")
    if not os.path.exists(path):
        raise FileNotFoundError(f"‚ùå KB not found: {path}")
    with open(path, "r", encoding="utf-8") as f:
        txt = f.read()
    return re.sub(r"\r\n?", "\n", txt)

def split_paragraphs(text: str):
    parts = re.split(r"\n\s*\n", text)
    return [p.strip() for p in parts if len(p.strip()) > 40]

TOKEN_RE = re.compile(r"[A-Za-z–ê-–Ø–∞-—è–Å—ë0-9\-']+")
def tok(s: str): return [t.lower() for t in TOKEN_RE.findall(s)]

def retrieve(kb: str, question: str) -> str:
    print("üîç –í—ã–±–∏—Ä–∞—é —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç...")
    paras = split_paragraphs(kb)
    q = tok(question)
    qset = set([t for t in q if len(t) > 2])
    scored = []
    for p in paras:
        pt = tok(p)
        score = sum(1 for t in pt if t in qset)
        if score > 0:
            scored.append((score, p))
    selected = [p for _, p in sorted(scored, key=lambda x:x[0], reverse=True)[:10]]
    ctx = "\n\n".join(selected)
    print(f"üìå –ö–æ–Ω—Ç–µ–∫—Å—Ç –≤—ã–±—Ä–∞–Ω: {len(ctx)} —Å–∏–º–≤–æ–ª–æ–≤")
    return ctx

def call_model(role: str, question: str, context: str, previous: str = None):
    prompts = {
        "analyst": (
            "–¢—ã ‚Äî –ê–ù–ê–õ–ò–¢–ò–ö –ú–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–∞ –∞–ª–∏–∏ –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏. "
            "–ò–∑–≤–ª–µ–∫–∏ –∏–∑ –ö–û–ù–¢–ï–ö–°–¢–ê —Ç–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã –≤ –≤–∏–¥–µ —Å–ø–∏—Å–∫–∞. –ù–∏–∫–∞–∫–∏—Ö –ª–∏—à–Ω–∏—Ö —Å–ª–æ–≤."
        ),
        "communicator": (
            "–¢—ã ‚Äî –ö–û–ú–ú–£–ù–ò–ö–ê–¢–û–†. –í–æ–∑—å–º–∏ **—Ñ–∞–∫—Ç—ã –∞–Ω–∞–ª–∏—Ç–∏–∫–∞** –∏ –æ–±—ä—è—Å–Ω–∏ –∏—Ö –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º "
            "–∫–æ—Ä–æ—Ç–∫–∏–º–∏ –∞–±–∑–∞—Ü–∞–º–∏. –î–æ–±–∞–≤—å: –∫—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ + —á—Ç–æ –¥–µ–ª–∞—Ç—å –¥–∞–ª—å—à–µ (—á–µ–∫-–ª–∏—Å—Ç)."
        ),
        "manager": (
            "–¢—ã ‚Äî –ú–ï–ù–ï–î–ñ–ï–†. –û–±—ä–µ–¥–∏–Ω–∏ **—Ñ–∞–∫—Ç—ã** –∏ **–æ–±—ä—è—Å–Ω–µ–Ω–∏–µ** –≤ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π "
            "10-—Å—Ç—Ä–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è + —á—ë—Ç–∫–∏–π –ø–ª–∞–Ω –¥–µ–π—Å—Ç–≤–∏–π."
        )
    }

    messages = [
        {"role": "system", "content": "–ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –ö–û–ù–¢–ï–ö–°–¢."},
        {"role": "system", "content": f"–ö–û–ù–¢–ï–ö–°–¢:\n{context}"},
        {"role": "system", "content": prompts[role]},
        {"role": "user", "content": question}
    ]

    if previous:
        messages.append({"role": "system", "content": previous})

    print(f"‚è≥ –û—Ç–ø—Ä–∞–≤–ª—è—é –∑–∞–ø—Ä–æ—Å —Ä–æ–ª–∏: {role.upper()}...")

    try:
        r = client.chat.completions.create(model=MODEL, messages=messages)
        text = r.choices[0].message.content.strip()
        print(f"‚úÖ {role.upper()} –æ—Ç–≤–µ—Ç–∏–ª.\n")
        return text
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —É —Ä–æ–ª–∏ {role.upper()}: {e}")
        return f"–û—à–∏–±–∫–∞ —É —Ä–æ–ª–∏ {role.upper()}: –¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ."

def main():
    try:
        kb = load_kb(KB_PATH)
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ KB: {e}")
        sys.exit(1)

    while True:
        print("\n==================================================================")
        question = input(Fore.WHITE + "–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å:\n> ").strip()
        if not question:
            print("‚ö† –ü—É—Å—Ç–æ–π –≤–æ–ø—Ä–æ—Å, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
            continue

        context = retrieve(kb, question)
        if not context:
            print("‚ö† –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤–æ–ø—Ä–æ—Å—É.")
            continue

        # --- 3 –º–æ–¥–µ–ª–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ ---
        a_text = call_model("analyst", question, context)
        c_text = call_model("communicator", a_text, context)
        m_text = call_model("manager", question, context, f"–§–∞–∫—Ç—ã:\n{a_text}\n\n–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:\n{c_text}")

        print("\nüîé –†–ï–ó–£–õ–¨–¢–ê–¢:\n")
        print(Fore.MAGENTA + "=== –ê–ù–ê–õ–ò–¢–ò–ö ===\n" + a_text + "\n")
        print(Fore.GREEN + "=== –ö–û–ú–ú–£–ù–ò–ö–ê–¢–û–† ===\n" + c_text + "\n")
        print(Fore.YELLOW + "=== –ú–ï–ù–ï–î–ñ–ï–† (—Ñ–∏–Ω–∞–ª—å–Ω—ã–π) ===\n" + m_text + "\n")

        with open("report.txt", "a", encoding="utf-8") as f:
            f.write(f"\n–í–æ–ø—Ä–æ—Å:\n{question}\n")
            f.write("\n–ê–ù–ê–õ–ò–¢–ò–ö:\n" + a_text + "\n")
            f.write("\n–ö–û–ú–ú–£–ù–ò–ö–ê–¢–û–†:\n" + c_text + "\n")
            f.write("\n–ú–ï–ù–ï–î–ñ–ï–†:\n" + m_text + "\n")
            f.write("=" * 80 + "\n")

        print("‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ report.txt\n")

if __name__ == "__main__":
    main()
